<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>risks</title>
    <link rel="stylesheet" href="../styles/mystyles.css">
    <link rel="stylesheet" href="../styles/minimal-table.css">
<link rel="stylesheet" href="../styles/mystyles.css">
<script src="https://code.jquery.com/jquery-1.10.2.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">

  </head>


  <header>
    <nav style="width: 100%;">
      <label class="logo">The use and misuse of AI</label>
      <ul>
       <li><a class="active" href="../index.html">Home</a></li>
       <li>
        <a href="#">AI
        <i class="fas fa-caret-down"></i>
        </a>
        <ul>
           <li><a href="choices.html">Choices</a></li>
           <li><a href="opportunities.html">Opportunities</a></li>
           <li><a href="risks.html">Risks</a></li>
           <li><a href="ethics.html">Ethics of AI</a></li>
           <li><a href="references.html">References</a></li>
        </ul>
       </li>
       <li>
        <a href="#">Team details
        <i class="fas fa-caret-down"></i>
        </a>
        <ul>
          <section>
           <li><a href="team-formation.html">Team Formation</a>
           <li><a href="proposal.html">Topic Proposal</a> 
           <li><a href="evaluation.html">Peer Evaluation</a>
             <li><a href="meetings.html">Meeting Minutes</a>
             <li><a href="portfolio.html">Project Portfolio</a>
             <li><a href="rubric.html">Assessment Rubric</a>
             <li><a href="guidelines.html">Guideline Conformance</a>
             <li><a href="process.html">Process Support</a>  
        
             </section>
    
        </ul>
       </li>
    
      </ul>
    </nav>
    
    </header>
  <body class="col-lg-12 body_background">
  
<!--This page will cover the use and misuse of AI -->

<!-- Main content -->
<h1 style="color:#4343FF;">Technology Risks</h1>


<h4 style="color:#E0E0FF;">The page or area describing the risks posed by your chosen technology/topic.</h4>
<br>
<br>

<div style="color: darkgrey; margin: 0px 100px 100px 0px;"> 
  <h3 style="color:#4343FF;"><b>Current Malicious Uses</b></h3>
  <p>
    AI’s usefulness as a tool has lead to a multitude of varied applications.
  </p>
  <p>
    <b style="color: #A1A1FF;">Deepfakes</b> are the use of AI to create realistic video and/or audio. It uses AI’s ‘deep learning’ to first identify patterns in a subject’s voice, mannerisms, and physical features, then recreate them with astounding accuracy. This can be used to fake situations giving seemingly credible evidence that someone said something or did something. 
    <br>
    Uses could look like the manipulation of facial features to make it seem like someone was saying something they hadn’t said, with their voice recreated to match the visuals. Or maybe one person’s face was swapped with another’s.
    <br>
    In practice, deepfakes have the potential to be used for defamation, blackmail, and disinformation. They serve as a stark reminder not to trust everything on the internet. (Ciancaglini et al., 2020, pg. 52).
  </p>
  <p>
    The technology started gaining attention from the public in 2017, when deepfakes of celebrities such as Scarlett Johansson and Taylor Swift superimposed into adult videos were posted to Reddit. (Ciancaglini et al., 2020, pg. 53).
    <br>
    Unfortunately, since then, deepfake technology has continued to be used for non-consensual adult videos. By September 2019, AI firm Deeptrace had located 15,000 deepfake videos. Research Company, Sensity AI, has tracked deepfake videos from December 2018, and found that 90% - 95% were non-consensual adult videos, with 90% exploiting women. (Hao, 2021).
  </p>
  <p>
    It would be remiss to condemn this technology as a whole however. It has plenty of benign uses. In the automobile industry, AI generated video is used to simulate car accidents to teach autonomous cars to avoid errors. In the film industry, deepfakes have been used to take the place of deceased actors. In the medical industry, it has contributed towards creating artificial voice replacements for patients who lost their voices. (Ciancaglini et al., 2020, pg. 53).
  </p>
  <p>
    A second nefarious use is <b style="color: #A1A1FF;">AI-supported Password Guessing</b>. It helps by analysing password datasets and generating password variations that are statistically likely. Existing password hacking methods such as HashCat, compare password variations to the password hash. The use of AI alongside these, gives more accurate password guesses. (Ciancaglini et al., 2020, pg. 12).
    <br>
    Hacked accounts can result in a loss of private and sensitive details. Those with access to hacked accounts may use these details for blackmail or to impersonate the hacked user, often for financial gain or defamation.
  </p>
  <p>
    AI can also be used to <b style="color: #A1A1FF;">impersonate human behaviour</b>. They can copy human usage patterns and mimic these to avoid bot detection systems. These can be used to take advantage of monetization services on social media platforms in a form of fraud. One example is the taking advantage of Spotify’s monetization system to monetize a song. A huge group of bots could be used to listen to a select song, artificially generating traffic for the artist who would then receive more money. These bots, by mimicking human usage patterns, are able to escape detection. In this situation, the AI system could create playlists with various similar songs to simulate human-like musical tastes, rather than selecting music at random.  (Ciancaglini et al., 2020, pg. 19). 
  </p>
  <br>

  <h3 style="color:#4343FF;"><b>Current Malicious Uses</b></h3>
  <p>
    There are many future risks that can be anticipated concerning artificial intelligence. With AI being used more widely, <b style="color: #A1A1FF;">if anything causes the AI to fail</b>, this will negatively impact upon whatever the AI is helping. For example, if the AI in a chatbot failed, the chatbot feature would be broken. As a piece of software, AI could also be hacked, making it another <b style="color: #A1A1FF;">potential security risk</b>.
  </p>
  <p> 
    Like any tool, AI can be used to work towards both benign and malicious ends. This is a risk faced when coming up with any new technology. There are always ways technologies can be abused. Some likely scenarios involve more efficient, convincing scams, and the abuse of image recognition systems.
  </p>
  <p>
    Scammers could use AI to better convince their victims of their stories. A Machine Learning algorithm could learn to <b style="color: #A1A1FF;">anticipate what targets would reply to certain advances and aid the scammer in creating more persuasive stories</b>. 
    <br>
    It also isn’t unlikely that scammers could soon employ AI to <b style="color: #A1A1FF;">detect whether targets are likely to be deceived</b>, and to notify them when victims are unlikely to continue. This would allow them to give up on targets unlikely to fall for their pretences at an earlier stage, giving them more time to hit other targets. 
    <br>
    A common scam is where the scammers pretend to be an acquaintance stranded somewhere overseas without money. Using deepfake audio, scammers could <b style="color: #A1A1FF;">impersonate these people’s voices</b>. While the scam is so common that almost anyone would be immediately suspect of such a message as a text, a sound file would more than likely be convincing. (Ciancaglini et al., 2020, pg. 30-36).
  </p>
  <p>
    <b style="color: #A1A1FF;">Image recognition systems could be abused</b>. For example, current limitations of such systems could be taken advantage of to create traffic during emergencies. Autonomous cars are taught to recognise the elements of a road to teach them appropriate behaviour. Appropriate behaviour would include following road rules. 
    <br>
    Using this information, one could create a car trap with 2 circles, one inside the other. 
    <br>
    The first, outer circle would consist of broken lines which, according to road rules, you can cross over. 
    <br>
    The second, inner circle would be solid without gaps, which according to road rules, one cannot cross over. 
    <br>In cases where a solid line and broken lines run alongside each other, the rules state you can cross over from the side of the broken lines, but not from the side of the solid line. The car’s AI would therefore recognise the image of the broken lines and drive through it, but upon reaching the other side of the circle, the car would find a solid line and stop moving. This is illustrated on the figure below.
  </p>

  <img src="../images/cartrap.png"; style= "width:  400px; padding: 10px;">

  <p style="color: #E0E0FF;">
    Figure 1. A self-driving car trapped, having entered through broken lines and found itself stuck within a solid line circle.
    <br><br>
    Note: A recreation of a James Bridle photo Adapted from Malicious Uses and Abuses of Artificial Intelligence. Ciancaglini, V., Gibson, C., Sancho, D., McCarthy, O., Eira, M., Amann, P., Klayn, A. (November 19, 2020). Trend Micro Research.
  </p>
  
  <p>
    In such a case, the driver of the car would have to figure out what was wrong with their car and then manually override the system. During this time, traffic would inevitably build up behind them. Detour signs could also be employed at the same time to redirect cars and add to such traffic. If temporary detour signs were added, self-driving cars would recognise them and follow directions without human critical thinking to consider why exactly these was a detour and where the cause of it lay. Such techniques could be used during a bank robbery or terrorist attack to slow down the response times of emergency services. (Ciancaglini et al., 2020, pg 38-39).
  </p>
  <p>
    Currently, artificial intelligence lacks the computing power and algorithms for a ‘full artificial intelligence’ but we are slowly developing towards making it a reality. In the short term, AI could be used to replace humans in all sorts of applications, <b style="color: #A1A1FF;">destroying of millions of jobs</b>. (Cellan-Jones, 2014). In the far future, one possibility as stated by Stephen Hawking (2014), is that “The development of full artificial intelligence could spell the end of the human race.” According to Hawking, if AI were created that could match or surpass humans, “it would take off on its own and re-design itself at an ever increasing rate”. (Cellan-Jones, 2014). Since humans are limited biologically and since evolution is so slow, humanity would not be able to compete, and AI would take our place. If we were to develop a full artificial intelligence, Rollo Carpenter, creator of Cleverbot observed that, <b style="color: #A1A1FF;">“we can’t know if we’ll infinitely be helped by it, or ignored by it and sidelined, or conceivably destroyed by it”</b>. This unknown risk gives rise to a long term fear of AI, which has been voiced by Elon Musk, as “our biggest existential threat”. (Cellan-Jones, 2014).
  </p>
</div>


<!-- Sign and date the page, it's only polite! -->
<address style="color: #E0E0FF;">Updated June 5 2021<br>
  by Anthony Yuen</address>

</body>
</html>